{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_diabetes\n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LinearRegression'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearRegression().__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
       "         0.01990842, -0.01764613],\n",
       "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
       "        -0.06832974, -0.09220405],\n",
       "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
       "         0.00286377, -0.02593034],\n",
       "       ...,\n",
       "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
       "        -0.04687948,  0.01549073],\n",
       "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
       "         0.04452837, -0.02593034],\n",
       "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
       "        -0.00421986,  0.00306441]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "       220.,  57.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method to_json in module pandas.core.generic:\n",
      "\n",
      "to_json(path_or_buf: 'FilePathOrBuffer | None' = None, orient: 'str | None' = None, date_format: 'str | None' = None, double_precision: 'int' = 10, force_ascii: 'bool_t' = True, date_unit: 'str' = 'ms', default_handler: 'Callable[[Any], JSONSerializable] | None' = None, lines: 'bool_t' = False, compression: 'CompressionOptions' = 'infer', index: 'bool_t' = True, indent: 'int | None' = None, storage_options: 'StorageOptions' = None) -> 'str | None' method of pandas.core.frame.DataFrame instance\n",
      "    Convert the object to a JSON string.\n",
      "    \n",
      "    Note NaN's and None will be converted to null and datetime objects\n",
      "    will be converted to UNIX timestamps.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    path_or_buf : str or file handle, optional\n",
      "        File path or object. If not specified, the result is returned as\n",
      "        a string.\n",
      "    orient : str\n",
      "        Indication of expected JSON string format.\n",
      "    \n",
      "        * Series:\n",
      "    \n",
      "            - default is 'index'\n",
      "            - allowed values are: {'split', 'records', 'index', 'table'}.\n",
      "    \n",
      "        * DataFrame:\n",
      "    \n",
      "            - default is 'columns'\n",
      "            - allowed values are: {'split', 'records', 'index', 'columns',\n",
      "              'values', 'table'}.\n",
      "    \n",
      "        * The format of the JSON string:\n",
      "    \n",
      "            - 'split' : dict like {'index' -> [index], 'columns' -> [columns],\n",
      "              'data' -> [values]}\n",
      "            - 'records' : list like [{column -> value}, ... , {column -> value}]\n",
      "            - 'index' : dict like {index -> {column -> value}}\n",
      "            - 'columns' : dict like {column -> {index -> value}}\n",
      "            - 'values' : just the values array\n",
      "            - 'table' : dict like {'schema': {schema}, 'data': {data}}\n",
      "    \n",
      "            Describing the data, where data component is like ``orient='records'``.\n",
      "    \n",
      "    date_format : {None, 'epoch', 'iso'}\n",
      "        Type of date conversion. 'epoch' = epoch milliseconds,\n",
      "        'iso' = ISO8601. The default depends on the `orient`. For\n",
      "        ``orient='table'``, the default is 'iso'. For all other orients,\n",
      "        the default is 'epoch'.\n",
      "    double_precision : int, default 10\n",
      "        The number of decimal places to use when encoding\n",
      "        floating point values.\n",
      "    force_ascii : bool, default True\n",
      "        Force encoded string to be ASCII.\n",
      "    date_unit : str, default 'ms' (milliseconds)\n",
      "        The time unit to encode to, governs timestamp and ISO8601\n",
      "        precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,\n",
      "        microsecond, and nanosecond respectively.\n",
      "    default_handler : callable, default None\n",
      "        Handler to call if object cannot otherwise be converted to a\n",
      "        suitable format for JSON. Should receive a single argument which is\n",
      "        the object to convert and return a serialisable object.\n",
      "    lines : bool, default False\n",
      "        If 'orient' is 'records' write out line-delimited json format. Will\n",
      "        throw ValueError if incorrect 'orient' since others are not\n",
      "        list-like.\n",
      "    \n",
      "    compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None}\n",
      "    \n",
      "        A string representing the compression to use in the output file,\n",
      "        only used when the first argument is a filename. By default, the\n",
      "        compression is inferred from the filename.\n",
      "    index : bool, default True\n",
      "        Whether to include the index values in the JSON string. Not\n",
      "        including the index (``index=False``) is only supported when\n",
      "        orient is 'split' or 'table'.\n",
      "    indent : int, optional\n",
      "       Length of whitespace used to indent each record.\n",
      "    \n",
      "       .. versionadded:: 1.0.0\n",
      "    \n",
      "    storage_options : dict, optional\n",
      "        Extra options that make sense for a particular storage connection, e.g.\n",
      "        host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "        are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
      "        starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
      "        ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
      "    \n",
      "        .. versionadded:: 1.2.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    None or str\n",
      "        If path_or_buf is None, returns the resulting json format as a\n",
      "        string. Otherwise returns None.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    read_json : Convert a JSON string to pandas object.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The behavior of ``indent=0`` varies from the stdlib, which does not\n",
      "    indent the output but does insert newlines. Currently, ``indent=0``\n",
      "    and the default ``indent=None`` are equivalent in pandas, though this\n",
      "    may change in a future release.\n",
      "    \n",
      "    ``orient='table'`` contains a 'pandas_version' field under 'schema'.\n",
      "    This stores the version of `pandas` used in the latest revision of the\n",
      "    schema.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import json\n",
      "    >>> df = pd.DataFrame(\n",
      "    ...     [[\"a\", \"b\"], [\"c\", \"d\"]],\n",
      "    ...     index=[\"row 1\", \"row 2\"],\n",
      "    ...     columns=[\"col 1\", \"col 2\"],\n",
      "    ... )\n",
      "    \n",
      "    >>> result = df.to_json(orient=\"split\")\n",
      "    >>> parsed = json.loads(result)\n",
      "    >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      "    {\n",
      "        \"columns\": [\n",
      "            \"col 1\",\n",
      "            \"col 2\"\n",
      "        ],\n",
      "        \"index\": [\n",
      "            \"row 1\",\n",
      "            \"row 2\"\n",
      "        ],\n",
      "        \"data\": [\n",
      "            [\n",
      "                \"a\",\n",
      "                \"b\"\n",
      "            ],\n",
      "            [\n",
      "                \"c\",\n",
      "                \"d\"\n",
      "            ]\n",
      "        ]\n",
      "    }\n",
      "    \n",
      "    Encoding/decoding a Dataframe using ``'records'`` formatted JSON.\n",
      "    Note that index labels are not preserved with this encoding.\n",
      "    \n",
      "    >>> result = df.to_json(orient=\"records\")\n",
      "    >>> parsed = json.loads(result)\n",
      "    >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      "    [\n",
      "        {\n",
      "            \"col 1\": \"a\",\n",
      "            \"col 2\": \"b\"\n",
      "        },\n",
      "        {\n",
      "            \"col 1\": \"c\",\n",
      "            \"col 2\": \"d\"\n",
      "        }\n",
      "    ]\n",
      "    \n",
      "    Encoding/decoding a Dataframe using ``'index'`` formatted JSON:\n",
      "    \n",
      "    >>> result = df.to_json(orient=\"index\")\n",
      "    >>> parsed = json.loads(result)\n",
      "    >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      "    {\n",
      "        \"row 1\": {\n",
      "            \"col 1\": \"a\",\n",
      "            \"col 2\": \"b\"\n",
      "        },\n",
      "        \"row 2\": {\n",
      "            \"col 1\": \"c\",\n",
      "            \"col 2\": \"d\"\n",
      "        }\n",
      "    }\n",
      "    \n",
      "    Encoding/decoding a Dataframe using ``'columns'`` formatted JSON:\n",
      "    \n",
      "    >>> result = df.to_json(orient=\"columns\")\n",
      "    >>> parsed = json.loads(result)\n",
      "    >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      "    {\n",
      "        \"col 1\": {\n",
      "            \"row 1\": \"a\",\n",
      "            \"row 2\": \"c\"\n",
      "        },\n",
      "        \"col 2\": {\n",
      "            \"row 1\": \"b\",\n",
      "            \"row 2\": \"d\"\n",
      "        }\n",
      "    }\n",
      "    \n",
      "    Encoding/decoding a Dataframe using ``'values'`` formatted JSON:\n",
      "    \n",
      "    >>> result = df.to_json(orient=\"values\")\n",
      "    >>> parsed = json.loads(result)\n",
      "    >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      "    [\n",
      "        [\n",
      "            \"a\",\n",
      "            \"b\"\n",
      "        ],\n",
      "        [\n",
      "            \"c\",\n",
      "            \"d\"\n",
      "        ]\n",
      "    ]\n",
      "    \n",
      "    Encoding with Table Schema:\n",
      "    \n",
      "    >>> result = df.to_json(orient=\"table\")\n",
      "    >>> parsed = json.loads(result)\n",
      "    >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      "    {\n",
      "        \"schema\": {\n",
      "            \"fields\": [\n",
      "                {\n",
      "                    \"name\": \"index\",\n",
      "                    \"type\": \"string\"\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"col 1\",\n",
      "                    \"type\": \"string\"\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"col 2\",\n",
      "                    \"type\": \"string\"\n",
      "                }\n",
      "            ],\n",
      "            \"primaryKey\": [\n",
      "                \"index\"\n",
      "            ],\n",
      "            \"pandas_version\": \"0.20.0\"\n",
      "        },\n",
      "        \"data\": [\n",
      "            {\n",
      "                \"index\": \"row 1\",\n",
      "                \"col 1\": \"a\",\n",
      "                \"col 2\": \"b\"\n",
      "            },\n",
      "            {\n",
      "                \"index\": \"row 2\",\n",
      "                \"col 1\": \"c\",\n",
      "                \"col 2\": \"d\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.DataFrame(X).to_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_json = pd.DataFrame(X).to_json(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_json = pd.Series(y).to_json(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
       "         0.01990842, -0.01764613],\n",
       "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
       "        -0.06832974, -0.09220405],\n",
       "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
       "         0.00286377, -0.02593034],\n",
       "       ...,\n",
       "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
       "        -0.04687948,  0.01549073],\n",
       "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
       "         0.04452837, -0.02593034],\n",
       "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
       "        -0.00421986,  0.00306441]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json(X_json, orient='records', typ='frame').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      151\n",
       "1       75\n",
       "2      141\n",
       "3      206\n",
       "4      135\n",
       "      ... \n",
       "437    178\n",
       "438    104\n",
       "439    132\n",
       "440    220\n",
       "441     57\n",
       "Length: 442, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json(y_json, orient='records', typ='series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zzz</td>\n",
       "      <td>zzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yyy</td>\n",
       "      <td>yyy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  col1 col2\n",
       "0  zzz  zzz\n",
       "1  yyy  yyy"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_records([{'col1': 'zzz', 'col2': 'zzz'}, {'col1': 'yyy', 'col2': 'yyy'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([1]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: x!=1, [1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask_restx import fields, marshal\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fields = dict()\n",
    "train_fields['hyperparameters'] = {'*': wild}\n",
    "train_fields['X'] = fields.List(fields.Dict)\n",
    "train_fields['y'] = fields.List(fields.Any)\n",
    "\n",
    "data = {'name': 'bob', 'addr1': '123 fake street', 'addr2': '', 'city': 'New York', 'state': 'NY', 'zip': '10468'}\n",
    "json.dumps(marshal(data, resource_fields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "wild = fields.Wildcard(fields.Raw)\n",
    "wild_2 = fields.Wildcard(fields.Raw)\n",
    "train_fields = {\n",
    "    'hyperparameters': wild,\n",
    "    'X': fields.List(fields.Raw),\n",
    "    'y': fields.List(fields.Raw)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"c2\": 3, \"c1\": 1}'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = {'c1': 1, 'c2': 3}\n",
    "wk = fields.Wildcard(fields.Raw)\n",
    "tm = {'*' : wk}\n",
    "json.dumps(marshal(t, tm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "wild = fields.Wildcard(fields.Raw)\n",
    "train_fields = {\n",
    "    'hyperparameters': wild,\n",
    "    'X': fields.List(fields.Raw),\n",
    "    'y': fields.List(fields.Raw)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"hyperparameters\": {}, \"X\": [{\"c1\": 1, \"c2\": 3}, {\"c1\": 0, \"c2\": 13}, {\"c1\": -3, \"c2\": 3.5}], \"y\": [1, 2, 3]}'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(marshal(data, train_fields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deDeprecationWarning'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = ('de''DeprecationWarning')\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'dict' and 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/63/q32zgnw527g9547scbl9tby00000gn/T/ipykernel_88042/564318624.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m{\u001b[0m\u001b[0;34m'1'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'23'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m23\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'dict' and 'dict'"
     ]
    }
   ],
   "source": [
    "{'1' : 1, '2' : 2} + {'23' : 23}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('avito')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a2341f07fff404428c0ad202c85fe1ba8adbd1e5f585695f92e98a112079c69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
